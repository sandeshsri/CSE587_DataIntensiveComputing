{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Predicitve_Analytics.py\n",
    "\"\"\"\n",
    "#Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def Accuracy(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float    \n",
    "    \"\"\"\n",
    "    cm = ConfusionMatrix(y_true,y_pred)\n",
    "    correct = np.trace(cm)\n",
    "    total = cm.sum()\n",
    "    acc=0\n",
    "    if(total>0):\n",
    "        acc = correct/total\n",
    "    return acc\n",
    "\n",
    "def Recall(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    cm = ConfusionMatrix(y_true,y_pred)\n",
    "    classes = cm.shape[0]\n",
    "    col = cm.sum(axis=1)\n",
    "    sum1=0\n",
    "    for i in range(classes):\n",
    "        divisor = col[i]\n",
    "        if(divisor!=0):\n",
    "            sum1+=cm[i][i]/divisor\n",
    "    re=0\n",
    "    if(classes>0):\n",
    "        re = sum1/classes\n",
    "    return re\n",
    "\n",
    "def Precision(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float    \n",
    "    \"\"\"\n",
    "    cm = ConfusionMatrix(y_true,y_pred)\n",
    "    classes = cm.shape[0]\n",
    "    col = cm.sum(axis=0)\n",
    "    sum1=0\n",
    "    for i in range(classes):\n",
    "        divisor = col[i]\n",
    "        if(divisor!=0):\n",
    "            sum1+=cm[i][i]/divisor\n",
    "    pre=0\n",
    "    if(classes>0):\n",
    "        pre = sum1/classes\n",
    "    return pre\n",
    "\n",
    "def WCSS(Clusters):\n",
    "    \"\"\"\n",
    "    :Clusters List[numpy.ndarray]\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "def ConfusionMatrix(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    #For 0-10 range\n",
    "    un = np.unique(y_true)\n",
    "    y_true=y_true-un[0]\n",
    "    un = np.unique(y_pred)\n",
    "    y_pred=y_pred-un[0]\n",
    "    classes = len(np.unique(np.concatenate((y_true,y_pred))))        \n",
    "    mul = y_true*classes\n",
    "    sum1 = mul+y_pred    \n",
    "    x,bins= np.histogram(sum1,bins=np.arange(classes**2+1))\n",
    "    mat = x.reshape(classes, classes)\n",
    "    return(mat)\n",
    "\n",
    "def KNN(X_train,X_test,Y_train, K):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    :type K: int\n",
    "   \n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    #K = 20 #int(input(\"value of K:\"))\n",
    "\n",
    "    dists = np.sum(X_train**2,axis=1) + np.sum(X_test**2, axis=1)[:, np.newaxis] - 2*np.dot(X_test,X_train.T)\n",
    "\n",
    "    sorted_distance = np.argsort(dists, axis=1)\n",
    "\n",
    "    top_k_neigh = sorted_distance[:,:K]\n",
    "   \n",
    "    pred_labels = []\n",
    "    for i in top_k_neigh:\n",
    "        c, cot = np.unique(Y_train[i], return_counts = True)\n",
    "        ind = np.argmax(cot)\n",
    "        pred_labels.append(c[ind])\n",
    "\n",
    "    pred_labels = np.asarray(pred_labels)\n",
    "\n",
    "    return pred_labels\n",
    "\n",
    "def RandomForest(X_train,Y_train,X_test):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    \n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    \n",
    "def PCA(X_train,N):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type N: int\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    #standardizing data \n",
    "    sc = StandardScaler()\n",
    "    std_data = sc.fit_transform(X_train)\n",
    "    pca_data = pd.DataFrame(std_data)\n",
    "\n",
    "    #Construct Covariance Matrix(C)\n",
    "    transpose_data = pca_data.T\n",
    "    C = np.cov(transpose_data)\n",
    "\n",
    "\n",
    "    #Decomposing C to eigen vectors and values\n",
    "    e_val, e_vec =  np.linalg.eig(C)\n",
    "\n",
    "\n",
    "    #N = int(input(\"Reduced Deminsions:\")) ------ Passed on to tge function\n",
    "\n",
    "    #Estimating High-valued Eigen vectors\n",
    "    eval_sorted = np.argsort(e_val)\n",
    "    top_evals = eval_sorted[::-1][:N]\n",
    "    high_valued_vectors = e_vec[:,top_evals]\n",
    "\n",
    "    PCA = np.empty([pca_data.shape[0], high_valued_vectors.shape[1]])\n",
    "    i = 0\n",
    "    for v in high_valued_vectors.T:\n",
    "            PCA[:,i] = np.dot(pca_data, v.T)\n",
    "            i += 1\n",
    "    return PCA\n",
    "    \n",
    "#TODO: Rename to Kmeans\n",
    "def Kmeans_py(X_train,N):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type N: int\n",
    "    :rtype: List[numpy.ndarray]\n",
    "    \"\"\"    \n",
    "    #Parameters\n",
    "    labels = np.zeros(train_y.shape) #Initial assignment of labels\n",
    "    centroids = X_train[np.random.choice(X_train.shape[0], N, replace=False)] #Random initialization of centroids\n",
    "    old_centroids = X_train[np.random.choice(X_train.shape[0], N, replace=False)] #Random initialization of centroids\n",
    "    \n",
    "    clusters = [[] for x in range(N)]\n",
    "    max_iter = 200\n",
    "\n",
    "    for iteration in range(max_iter):\n",
    "        iteration += 1\n",
    "        old_centroids = centroids\n",
    "        \n",
    "        #Calculating the euclidean distance of datapoints to the centroids\n",
    "        dist = np.zeros((N, X_train.shape[0]))\n",
    "        for i in range(len(centroids)):\n",
    "            dist[i] = np.linalg.norm(X_train - old_centroids[i], axis=1)\n",
    "        \n",
    "        dist = dist.transpose()\n",
    "        labels = np.argmin(dist, axis=1)\n",
    "        \n",
    "        #Clustering of datapoint based on euclidean distance to centroids\n",
    "        cls_ind = [[] for x in range(N)]\n",
    "        for l in range(N):\n",
    "            cls_ind[l] = [i for i,x in enumerate(labels) if x == l]\n",
    "        \n",
    "        clstr = [[] for x in range(N)]\n",
    "        for i in range(N):\n",
    "            clstr[i] = [X_train[idx] for idx in cls_ind[i]]\n",
    "            \n",
    "        clstr = np.array(clstr)\n",
    "        for i in range(N):\n",
    "            centroids[i] = np.mean(clstr[i])\n",
    "        clusters = clstr\n",
    "    return clusters\n",
    "    \n",
    "def SVM(X_train,Y_train,X_test):\n",
    "    DIC_svm =  SVC(kernel='linear',gamma='scale')\n",
    "    DIC_svm.fit(X_train,Y_train)\n",
    "    return(DIC_svm.predict(X_test))\n",
    "   \n",
    "def LR(X_train,Y_train,X_test):\n",
    "    DIC_logisticRegression = LogisticRegression(solver='lbfgs',multi_class='auto',max_iter=7500)\n",
    "    DIC_logisticRegression.fit(X_train,Y_train)\n",
    "    return(DIC_logisticRegression.predict(X_test))\n",
    "\n",
    "def DT(X_train,Y_train,X_test):\n",
    "    DIC_decisionTreeClassifier = DecisionTreeClassifier()\n",
    "    DIC_decisionTreeClassifier.fit(X_train,Y_train)\n",
    "    print(\"Depth\")\n",
    "    print(DIC_decisionTreeClassifier.tree_.max_depth)\n",
    "    return(DIC_decisionTreeClassifier.predict(X_test))\n",
    "\n",
    "def KNN_sk(X_train,Y_train,X_test,k=7):\n",
    "    DIC_KNN = KNeighborsClassifier(n_neighbors=k)\n",
    "    DIC_KNN.fit(X_train,Y_train)\n",
    "    KNNResult = DIC_KNN.predict(X_test)\n",
    "    return DIC_KNN.predict(X_test)\n",
    "\n",
    "def ensemble(X_train,Y_train,X_test):\n",
    "    classifierSVC = SVC(kernel='linear')\n",
    "    classifierLR = LogisticRegression(solver='lbfgs',multi_class='auto',max_iter=7500)\n",
    "    classifierDT = DecisionTreeClassifier()\n",
    "    classifierKNN = KNeighborsClassifier(n_neighbors=250)    \n",
    "    ensembleVC = VotingClassifier(estimators=[(\"SVM\",classifierSVC),(\"LR\",classifierLR),\n",
    "                                              (\"DT\",classifierDT),(\"KNN\",classifierKNN)],voting='hard')\n",
    "    ensembleVC.fit(X_train,Y_train)\n",
    "    return(ensembleVC.predict(X_test))\n",
    "\n",
    "#def SklearnSupervisedLearning(X_train,Y_train,X_test):\n",
    "def SklearnSupervisedLearning(X_train,Y_train,X_test,Y_test):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray    \n",
    "    :rtype: List[numpy.ndarray] \n",
    "    \"\"\"    \n",
    "    N,C= X_test.shape\n",
    "    result = []\n",
    "     \n",
    "    #SVM \n",
    "    SVMResult = SVM(X_train,Y_train,X_test)\n",
    "    print(\"SVM accuracy : %f\" %Accuracy(Y_test,SVMResult))\n",
    "    result.append(SVMResult)\n",
    "    \n",
    "    #LR\n",
    "    LRResult = LR(X_train,Y_train,X_test)\n",
    "    print(\"Logisitic Regression accuracy : %f\" %Accuracy(Y_test,LRResult))\n",
    "    result.append(LRResult)\n",
    "    \n",
    "    #Decision Tree\n",
    "    DTResult = DT(X_train,Y_train,X_test)\n",
    "    print(\"Decision Tree accuracy : %f\" %Accuracy(Y_test,DTResult))\n",
    "    result.append(DTResult)\n",
    "    \n",
    "    #KNN\n",
    "    KNNResult = KNN_sk(X_train,Y_train,X_test)\n",
    "    result.append(KNNResult)\n",
    "    \n",
    "    return result\n",
    "    \n",
    "#def SklearnVotingClassifier(X_train,Y_train,X_test):\n",
    "def SklearnVotingClassifier(X_train,Y_train,X_test,Y_test):    \n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray    \n",
    "    :rtype: List[numpy.ndarray] \n",
    "    \"\"\"\n",
    "    ensembleResult = ensemble(X_train,Y_train,X_test)\n",
    "    print(\"Voting Classifier accuracy : %f\" %ensembleVC.score(X_test,Y_test))\n",
    "    return ensembleResult\n",
    "\n",
    "def subPlotConfusionMatrixElement(ax,confusionMatrix,text):\n",
    "    ax.matshow(confusionMatrix)\n",
    "    ax.title.set_text(text)\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "def PlotConfusionMatrix(X_train,Y_train,X_test,Y_test):\n",
    "    \"\"\"\n",
    "    SVMResult = SVM(X_train,Y_train,X_test)\n",
    "    LRResult = LR(X_train,Y_train,X_test)\n",
    "    DTResult = DT(X_train,Y_train,X_test)\n",
    "    KNNResult = KNN_sk(X_train,Y_train,X_test,Y_test)\n",
    "    ensembleResult = ensemble(X_train,Y_train,X_test)\n",
    "    \"\"\"\n",
    "    #TODO- Remove. Only for testing.\n",
    "    SVMResult = DT(X_train,Y_train,X_test)\n",
    "    LRResult = SVMResult\n",
    "    DTResult = SVMResult\n",
    "    KNNResult = SVMResult\n",
    "    ensembleResult = SVMResult      \n",
    "\n",
    "    cmSVM = ConfusionMatrix(Y_test,SVMResult)\n",
    "    cmLR = ConfusionMatrix(Y_test,LRResult)\n",
    "    cmDT = ConfusionMatrix(Y_test,DTResult)\n",
    "    cmKNN = ConfusionMatrix(Y_test,KNNResult)\n",
    "    cmEnsemble = ConfusionMatrix(Y_test,ensembleResult)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 5, sharex='col', sharey='row',figsize=(15, 4))\n",
    "    plt.suptitle('Confusion matrix Plots')\n",
    "    \n",
    "    subPlotConfusionMatrixElement(ax[0],cmSVM,\"SVM\")\n",
    "    subPlotConfusionMatrixElement(ax[1],cmLR,\"Logistic Regression\")\n",
    "    subPlotConfusionMatrixElement(ax[2],cmDT,\"Decision Tree\")\n",
    "    subPlotConfusionMatrixElement(ax[3],cmKNN,\"K Nearest Neighbors\")\n",
    "    subPlotConfusionMatrixElement(ax[4],cmEnsemble,\"Ensemble\")\n",
    "    \n",
    "    #print(fig)\n",
    "    \n",
    "def PlotGridSearchElement(ax,plt_X,plt_Y,title):\n",
    "    ax.plot(plt_X,plt_Y)\n",
    "    ax.title.set_text(title)\n",
    "    \n",
    "def GridSearchUtil(X_train, Y_train,function,tuned_parameters):\n",
    "    gridSearch = GridSearchCV(function, tuned_parameters,cv=5)\n",
    "    gridSearch.fit(X_train, Y_train) \n",
    "    return(gridSearch.cv_results_['mean_test_score'])\n",
    "\n",
    "def GridSearch(X_train,Y_train,X_test,Y_test):\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, sharex='col', sharey='row',figsize=(15, 4))\n",
    "    plt.suptitle('Grid Search Parameters Plot')\n",
    "    \n",
    "    plt_X = [1,5,10,15]\n",
    "    tuned_parameters = [{'C': plt_X}]\n",
    "    plt_Y = GridSearchUtil(X_train, Y_train,SVC(kernel='linear',gamma='scale'),tuned_parameters)\n",
    "    PlotGridSearchElement(ax[0],plt_X,plt_Y,\"SVM\")\n",
    "    \n",
    "    plt_X = [5,10,15,20]\n",
    "    tuned_parameters = [{'max_depth': plt_X}]\n",
    "    plt_Y = GridSearchUtil(X_train, Y_train,DecisionTreeClassifier(),tuned_parameters)\n",
    "    PlotGridSearchElement(ax[1],plt_X,plt_Y,\"Decision Tree\")\n",
    "    \n",
    "    plt_X = [2,10,15,20]\n",
    "    tuned_parameters = [{'n_neighbors': plt_X}]\n",
    "    plt_Y = GridSearchUtil(X_train, Y_train,KNeighborsClassifier(),tuned_parameters)\n",
    "    PlotGridSearchElement(ax[2],plt_X,plt_Y,\"K Nearest Neighbors\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading datafile\n",
    "data = pd.read_csv(\"data.csv\", header = None)\n",
    "data = data.drop(index=0) #Drops the column names\n",
    "#print(data.shape) #dimensions of the data\n",
    "#print(data)\n",
    "\n",
    "#Features and label extraction\n",
    "data_x = data.iloc[:, :48] #Features\n",
    "data_y = data.iloc[:, 48] #Labels\n",
    "from sklearn import preprocessing\n",
    "MinMaxScaler = preprocessing.MinMaxScaler()\n",
    "data_x = MinMaxScaler.fit_transform(data_x)\n",
    "\n",
    "#Splittiing data into train (80%) and test (20%)\n",
    "train_X, test_X, train_y, test_y = train_test_split(data_x, data_y, test_size = 0.2)\n",
    "#print(data.columns.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy : 0.891357\n",
      "Logisitic Regression accuracy : 0.871460\n",
      "Depth\n",
      "32\n",
      "Decision Tree accuracy : 0.982910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([10, 11,  8, ...,  4,  1,  7], dtype=int64),\n",
       " array([10, 11,  8, ...,  4,  1,  7], dtype=int64),\n",
       " array([ 2, 11,  8, ...,  4,  1,  7], dtype=int64),\n",
       " array([ 2, 11,  8, ...,  4,  1,  7], dtype=int64)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#API Calls\n",
    "SklearnSupervisedLearning(train_X,train_y,test_X,test_y)\n",
    "#SklearnVotingClassifier(train_X,train_y,test_X,test_y)\n",
    "#PlotConfusionMatrix(train_X,train_y,test_X,test_y)\n",
    "#GridSearch(train_X,train_y,test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing our and skLearn performance\n",
    "def test(X_train,Y_train,X_test,Y_test):\n",
    "    SVMResult = DT(X_train,Y_train,X_test)\n",
    "    print(\"SKLearn\")\n",
    "    from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "    #from sklearn.metrics import classification_report\n",
    "    #print(classification_report(Y_test,SVMResult))\n",
    "    from sklearn.metrics import precision_score\n",
    "    print(precision_score(Y_test,SVMResult, average='macro'))\n",
    "    from sklearn.metrics import recall_score\n",
    "    print(recall_score(Y_test,SVMResult, average='macro'))\n",
    "    from sklearn.cluster import KMeans\n",
    "    k = len(np.unique(Y_train))\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(Y_train.values.reshape(-1, 1))\n",
    "    a = kmeans.labels_\n",
    "    print(\"KMeans\")\n",
    "    print(kmeans.labels_)\n",
    "    print(\"KNN accuracy\")\n",
    "    kr = KNN_sk(X_train,Y_train,X_test,15)\n",
    "    print(Accuracy(Y_test,kr))\n",
    "\n",
    "    cmSVM1 = ConfusionMatrix(Y_test,SVMResult)\n",
    "    print(\"Our\")\n",
    "    print(cmSVM1)\n",
    "    print(Accuracy(Y_test,SVMResult))\n",
    "    print(Precision(Y_test,SVMResult))\n",
    "    print(Recall(Y_test,SVMResult))\n",
    "    print(\"KMeans\")\n",
    "    cluster_list = Kmeans(Y_train,k)\n",
    "    print(cluster_list)\n",
    "    print(\"KNN accuracy\")\n",
    "    kr = KNN(X_train,X_test,Y_train, 15)\n",
    "    print(Accuracy(Y_test,kr))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKLearn\n",
      "[[719   0   0   0   0  15   0   0   4   0   0]\n",
      " [  0 718   0   0   1   0   0   0   1  17   0]\n",
      " [  0   0 731   0   7   0   0   0   1   0   0]\n",
      " [  0   0   4 716   1   0   0   3   0   0   0]\n",
      " [  0   1  11   2 720   0   0  14   0   0   0]\n",
      " [ 18   2   0   0   0 718   0   0   9   0   0]\n",
      " [  0   0   0   0   0   0 753   0   0   0   0]\n",
      " [  0   0   0   1  17   0   0 692   0   0   0]\n",
      " [  5   0   0   0   0  13   0   0 736   1   0]\n",
      " [  0  16   0   0   0   0   0   0   0 760   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 765]]\n",
      "0.97998046875\n",
      "0.9799517906805928\n",
      "0.9799280042901746\n",
      "KMeans\n",
      "[ 8  6  3 ...  3 10  0]\n",
      "KNN accuracy\n",
      "0.982177734375\n",
      "Our\n",
      "[[719   0   0   0   0  15   0   0   4   0   0]\n",
      " [  0 718   0   0   1   0   0   0   1  17   0]\n",
      " [  0   0 731   0   7   0   0   0   1   0   0]\n",
      " [  0   0   4 716   1   0   0   3   0   0   0]\n",
      " [  0   1  11   2 720   0   0  14   0   0   0]\n",
      " [ 18   2   0   0   0 718   0   0   9   0   0]\n",
      " [  0   0   0   0   0   0 753   0   0   0   0]\n",
      " [  0   0   0   1  17   0   0 692   0   0   0]\n",
      " [  5   0   0   0   0  13   0   0 736   1   0]\n",
      " [  0  16   0   0   0   0   0   0   0 760   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 765]]\n",
      "0.97998046875\n",
      "0.9799517906805928\n",
      "0.9799280042901746\n",
      "KMeans\n",
      "None\n",
      "KNN accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sande\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1143: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.090087890625\n"
     ]
    }
   ],
   "source": [
    "test(train_X,train_y,test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
